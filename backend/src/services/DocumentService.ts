// src/services/DocumentService.ts

import { Knex } from 'knex';
import DocumentModel, { 
  Document, 
  DocumentIngestStatus, 
  CreateDocumentRequest,
  DocumentQueryOptions 
} from '@/models/Document';
import ProcessingJobModel, { 
  ProcessingJob, 
  JobType, 
  CreateJobRequest 
} from '@/models/ProcessingJob';
import UserModel from '@/models/User';
import { Database } from '@/utils/database';
import { FileUploadResult } from '@/services/FileUploadService';
import { getErrorMessage } from '@/utils/typescript-helpers';
import { JobStatus } from '../models/ProcessingJob';


/**
 * æ–‡æ¡£åˆ›å»ºè¯·æ±‚æ¥å£
 */
export interface CreateDocumentServiceRequest {
  userId: string;
  uploadResult: FileUploadResult;
  metadata?: Record<string, any>;
  parseConfig?: Record<string, any>;
  chunkConfig?: Record<string, any>;
}

/**
 * æ–‡æ¡£åˆ›å»ºç»“æœæ¥å£
 */
export interface CreateDocumentServiceResult {
  document: Document;
  existingDocument?: boolean;
  processingJob?: ProcessingJob;
  message: string;
}

/**
 * æ–‡æ¡£çŠ¶æ€æ›´æ–°è¯·æ±‚æ¥å£
 */
export interface UpdateDocumentStatusRequest {
  docId: string;
  status: DocumentIngestStatus;
  errorMessage?: string;
  metadata?: Record<string, any>;
  parseResults?: {
    pageCount?: number;
    language?: string;
    textLength?: number;
    tokenEstimate?: number;
  };
}

/**
 * æ–‡æ¡£æŸ¥è¯¢è¯·æ±‚æ¥å£
 */
export interface DocumentListRequest {
  userId: string;
  status?: DocumentIngestStatus;
  mimeType?: string;
  page?: number;
  limit?: number;
  sortBy?: 'created_at' | 'updated_at' | 'filename' | 'size_bytes';
  sortOrder?: 'asc' | 'desc';
}

/**
 * æ–‡æ¡£åˆ—è¡¨å“åº”æ¥å£
 */
export interface DocumentListResponse {
  documents: Document[];
  pagination: {
    current: number;
    total: number;
    pages: number;
    limit: number;
    hasNext: boolean;
    hasPrev: boolean;
  };
  statistics: {
    total: number;
    byStatus: Record<DocumentIngestStatus, number>;
    totalSize: number;
  };
}

/**
 * æ–‡æ¡£è¯¦æƒ…å“åº”æ¥å£
 */
export interface DocumentDetailResponse extends Document {
  downloadUrl?: string | undefined;
  processingJobs?: ProcessingJob[];
  canDownload: boolean;
  canDelete: boolean;
  canReprocess: boolean;
}

/**
 * æ–‡æ¡£æœåŠ¡ç±»
 * æä¾›æ–‡æ¡£ç›¸å…³çš„ä¸šåŠ¡é€»è¾‘å¤„ç†
 */
export class DocumentService {
  /**
   * åˆ›å»ºæ–‡æ¡£è®°å½•
   * @param request åˆ›å»ºè¯·æ±‚
   * @returns åˆ›å»ºç»“æœ
   */
  public static async createDocument(
    request: CreateDocumentServiceRequest
  ): Promise<CreateDocumentServiceResult> {
    return await Database.transaction(async (trx: Knex.Transaction) => {
      try {
        console.log(`ğŸ“„ å¼€å§‹åˆ›å»ºæ–‡æ¡£è®°å½•: ${request.uploadResult.originalName} (ç”¨æˆ·: ${request.userId})`);

        // éªŒè¯ç”¨æˆ·æ˜¯å¦å­˜åœ¨
        const user = await UserModel.findById(request.userId);
        if (!user) {
          throw new Error('ç”¨æˆ·ä¸å­˜åœ¨');
        }

        // æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒå†…å®¹çš„æ–‡æ¡£ï¼ˆå»é‡é€»è¾‘ï¼‰
        const existingDocument = await DocumentModel.findByUserAndHash(
          request.userId,
          request.uploadResult.contentHash
        );

        if (existingDocument) {
          console.log(`â™»ï¸ å‘ç°é‡å¤æ–‡æ¡£: ${existingDocument.doc_id} (${existingDocument.filename})`);
          
          // å¦‚æœæ˜¯å·²åˆ é™¤çš„æ–‡æ¡£ï¼Œæ¢å¤å®ƒ
          if (existingDocument.deleted_at) {
            const restoredDocument = await DocumentModel.restore(existingDocument.doc_id, trx);
            return {
              document: restoredDocument,
              existingDocument: true,
              message: 'æ–‡æ¡£å·²å­˜åœ¨ï¼Œå·²ä»å›æ”¶ç«™æ¢å¤'
            };
          }

          // è¿”å›ç°æœ‰æ–‡æ¡£
          return {
            document: existingDocument,
            existingDocument: true,
            message: 'æ–‡æ¡£å·²å­˜åœ¨ï¼Œè¿”å›ç°æœ‰æ–‡æ¡£'
          };
        }

        // å‡†å¤‡æ–‡æ¡£æ•°æ®
        const createDocumentRequest: CreateDocumentRequest = {
          user_id: request.userId,
          filename: request.uploadResult.originalName,
          content_hash: request.uploadResult.contentHash,
          mime_type: request.uploadResult.mimeType,
          size_bytes: request.uploadResult.size,
          storage_path: request.uploadResult.storagePath,
          storage_bucket: request.uploadResult.storageBucket,
          metadata: {
            upload_timestamp: new Date().toISOString(),
            original_upload_name: request.uploadResult.originalName,
            file_id: request.uploadResult.fileId,
            ...request.metadata
          },
          parse_config: request.parseConfig ?? {},
          chunk_config: {
            target_tokens: 400,
            max_tokens: 500,
            overlap_tokens: 60,
            respect_boundaries: true,
            ...request.chunkConfig
          }
        };

        // åˆ›å»ºæ–‡æ¡£è®°å½•
        const document = await DocumentModel.create(createDocumentRequest, trx);

        // åˆ›å»ºå¤„ç†ä½œä¸š
        const processingJob = await this.createProcessingJob(document, trx);

        console.log(`âœ… æ–‡æ¡£åˆ›å»ºæˆåŠŸ: ${document.doc_id} (${document.filename})`);

        return {
          document,
          existingDocument: false,
          processingJob,
          message: 'æ–‡æ¡£åˆ›å»ºæˆåŠŸï¼Œå·²åŠ å…¥å¤„ç†é˜Ÿåˆ—'
        };

      } catch (error) {
        console.error('åˆ›å»ºæ–‡æ¡£å¤±è´¥:', error);
        throw new Error(`åˆ›å»ºæ–‡æ¡£å¤±è´¥: ${getErrorMessage(error)}`);
      }
    });
  }

  /**
   * è·å–æ–‡æ¡£è¯¦æƒ…
   * @param docId æ–‡æ¡£ID
   * @param userId ç”¨æˆ·ID
   * @param includeJobs æ˜¯å¦åŒ…å«å¤„ç†ä½œä¸šä¿¡æ¯
   * @returns æ–‡æ¡£è¯¦æƒ…
   */
  public static async getDocumentDetail(
    docId: string,
    userId: string,
    includeJobs: boolean = true
  ): Promise<DocumentDetailResponse | null> {
    try {
      // è·å–æ–‡æ¡£åŸºæœ¬ä¿¡æ¯
      const document = await DocumentModel.findById(docId);
      if (!document) {
        return null;
      }

      // éªŒè¯ç”¨æˆ·æƒé™
      if (document.user_id !== userId) {
        throw new Error('æ— æƒé™è®¿é—®è¯¥æ–‡æ¡£');
      }

      // è·å–å¤„ç†ä½œä¸šä¿¡æ¯
      let processingJobs: ProcessingJob[] = [];
      if (includeJobs) {
        processingJobs = await ProcessingJobModel.findByDocument(docId, {}, 10, 0);
      }

      // è·å–ä¸‹è½½URLï¼ˆå¦‚æœæ–‡æ¡£å¯ä¸‹è½½ï¼‰
      let downloadUrl: string | undefined;
      if (document.ingest_status !== DocumentIngestStatus.FAILED) {
        try {
          const { storageService } = await import('@/services/StorageService');
          downloadUrl = await storageService.getFileUrl(
            document.storage_bucket,
            document.storage_path,
            3600 // 1å°æ—¶æœ‰æ•ˆæœŸ
          );
        } catch (error) {
          console.warn('è·å–ä¸‹è½½URLå¤±è´¥:', error);
        }
      }

      // ç¡®å®šæƒé™
      const canDownload = document.ingest_status !== DocumentIngestStatus.FAILED;
      const canDelete = true; // ç”¨æˆ·å§‹ç»ˆå¯ä»¥åˆ é™¤è‡ªå·±çš„æ–‡æ¡£
      const canReprocess = [
        DocumentIngestStatus.FAILED,
        DocumentIngestStatus.PARSED,
        DocumentIngestStatus.CHUNKED,
        DocumentIngestStatus.READY
      ].includes(document.ingest_status);

      const documentDetail: DocumentDetailResponse = {
        ...document,
        downloadUrl,
        processingJobs,
        canDownload,
        canDelete,
        canReprocess
      };

      return documentDetail;

    } catch (error) {
      console.error('è·å–æ–‡æ¡£è¯¦æƒ…å¤±è´¥:', error);
      throw new Error(`è·å–æ–‡æ¡£è¯¦æƒ…å¤±è´¥: ${getErrorMessage(error)}`);
    }
  }

  /**
   * è·å–ç”¨æˆ·æ–‡æ¡£åˆ—è¡¨
   * @param request æŸ¥è¯¢è¯·æ±‚
   * @returns æ–‡æ¡£åˆ—è¡¨
   */
  public static async getDocumentList(
    request: DocumentListRequest
  ): Promise<DocumentListResponse> {
    try {
      const page = request.page || 1;
      const limit = Math.min(request.limit || 20, 100); // æœ€å¤§100æ¡
      const offset = (page - 1) * limit;

      // æ„å»ºæŸ¥è¯¢é€‰é¡¹
      const queryOptions: DocumentQueryOptions = {
        ...(request.status !== undefined ? { status: request.status } : {}),
        ...(request.mimeType !== undefined ? { mimeType: request.mimeType } : {}),
        sortBy: request.sortBy || 'created_at',
        sortOrder: request.sortOrder || 'desc'
      };

      // è·å–æ–‡æ¡£åˆ—è¡¨
      const documents = await DocumentModel.findByUser(
        request.userId,
        queryOptions,
        limit,
        offset
      );

      // è·å–æ€»æ•°ï¼ˆç”¨äºåˆ†é¡µï¼‰
      const totalQuery = await DocumentModel.findByUser(
        request.userId,
        queryOptions,
        999999,
        0
      );
      const total = totalQuery.length;

      // è®¡ç®—åˆ†é¡µä¿¡æ¯
      const pages = Math.ceil(total / limit);
      const pagination = {
        current: page,
        total,
        pages,
        limit,
        hasNext: page < pages,
        hasPrev: page > 1
      };

      // è·å–ç»Ÿè®¡ä¿¡æ¯
      const statistics = await DocumentModel.getStats(request.userId);

      return {
        documents,
        pagination,
        statistics
      };

    } catch (error) {
      console.error('è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥:', error);
      throw new Error(`è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: ${getErrorMessage(error)}`);
    }
  }

  /**
   * æ›´æ–°æ–‡æ¡£çŠ¶æ€
   * @param request æ›´æ–°è¯·æ±‚
   * @returns æ›´æ–°åçš„æ–‡æ¡£
   */
  public static async updateDocumentStatus(
    request: UpdateDocumentStatusRequest
  ): Promise<Document | null> {
    try {
      // å‡†å¤‡æ›´æ–°æ•°æ®
      const updateData: any = {
        ingest_status: request.status
      };

      // æ·»åŠ è§£æç»“æœ
      if (request.parseResults) {
        Object.assign(updateData, request.parseResults);
      }

      // æ·»åŠ å…ƒæ•°æ®
      if (request.metadata) {
        const existingDoc = await DocumentModel.findById(request.docId);
        if (existingDoc) {
          updateData.metadata = {
            ...existingDoc.metadata,
            ...request.metadata
          };
        } else {
          updateData.metadata = request.metadata;
        }
      }

      // æ›´æ–°æ–‡æ¡£çŠ¶æ€
      const updatedDocument = await DocumentModel.update(request.docId, updateData);

      if (updatedDocument) {
        console.log(`ğŸ“Š æ–‡æ¡£çŠ¶æ€å·²æ›´æ–°: ${request.docId} -> ${request.status}`);
      }

      return updatedDocument;

    } catch (error) {
      console.error('æ›´æ–°æ–‡æ¡£çŠ¶æ€å¤±è´¥:', error);
      throw new Error(`æ›´æ–°æ–‡æ¡£çŠ¶æ€å¤±è´¥: ${getErrorMessage(error)}`);
    }
  }

  /**
   * åˆ é™¤æ–‡æ¡£
   * @param docId æ–‡æ¡£ID
   * @param userId ç”¨æˆ·ID
   * @param permanent æ˜¯å¦æ°¸ä¹…åˆ é™¤
   * @returns æ˜¯å¦åˆ é™¤æˆåŠŸ
   */
  public static async deleteDocument(
    docId: string,
    userId: string,
    permanent: boolean = false
  ): Promise<boolean> {
    return await Database.transaction(async (trx: Knex.Transaction) => {
      try {
        // éªŒè¯æ–‡æ¡£å­˜åœ¨ä¸”å±äºç”¨æˆ·
        const document = await DocumentModel.findById(docId);
        if (!document) {
          throw new Error('æ–‡æ¡£ä¸å­˜åœ¨');
        }

        if (document.user_id !== userId) {
          throw new Error('æ— æƒé™åˆ é™¤è¯¥æ–‡æ¡£');
        }

        if (permanent) {
          // æ°¸ä¹…åˆ é™¤ï¼šåˆ é™¤å­˜å‚¨æ–‡ä»¶å’Œæ•°æ®åº“è®°å½•
          const { storageService } = await import('@/services/StorageService');
          await storageService.deleteFile(document.storage_bucket, document.storage_path);

          // åˆ é™¤ç›¸å…³çš„å¤„ç†ä½œä¸šè®°å½•
          // TODO: åœ¨å®ç°äº†ç›¸å…³æ¨¡å‹åå–æ¶ˆæ³¨é‡Š
          // await ProcessingJobModel.deleteByDocument(docId, trx);

          // åˆ é™¤æ•°æ®åº“è®°å½•ï¼ˆè¿™é‡Œéœ€è¦çœŸå®åˆ é™¤ï¼Œä¸æ˜¯è½¯åˆ é™¤ï¼‰
          // TODO: å®ç° hardDelete æ–¹æ³•
          console.log(`ğŸ—‘ï¸ æ°¸ä¹…åˆ é™¤æ–‡æ¡£: ${docId}`);
        } else {
          // è½¯åˆ é™¤
          await DocumentModel.softDelete(docId, trx);
          console.log(`ğŸ“¦ è½¯åˆ é™¤æ–‡æ¡£: ${docId}`);
        }

        return true;

      } catch (error) {
        console.error('åˆ é™¤æ–‡æ¡£å¤±è´¥:', error);
        throw new Error(`åˆ é™¤æ–‡æ¡£å¤±è´¥: ${getErrorMessage(error)}`);
      }
    });
  }

  /**
   * é‡æ–°å¤„ç†æ–‡æ¡£
   * @param docId æ–‡æ¡£ID
   * @param userId ç”¨æˆ·ID
   * @param jobTypes è¦é‡æ–°æ‰§è¡Œçš„ä½œä¸šç±»å‹
   * @returns åˆ›å»ºçš„å¤„ç†ä½œä¸š
   */
  public static async reprocessDocument(
    docId: string,
    userId: string,
    jobTypes?: JobType[]
  ): Promise<ProcessingJob[]> {
    return await Database.transaction(async (trx: Knex.Transaction) => {
      try {
        // éªŒè¯æ–‡æ¡£
        const document = await DocumentModel.findById(docId);
        if (!document) {
          throw new Error('æ–‡æ¡£ä¸å­˜åœ¨');
        }

        if (document.user_id !== userId) {
          throw new Error('æ— æƒé™é‡æ–°å¤„ç†è¯¥æ–‡æ¡£');
        }

        // æ£€æŸ¥æ–‡æ¡£çŠ¶æ€
        if (document.ingest_status === DocumentIngestStatus.UPLOADING ||
            document.ingest_status === DocumentIngestStatus.PARSING ||
            document.ingest_status === DocumentIngestStatus.CHUNKING) {
          throw new Error('æ–‡æ¡£æ­£åœ¨å¤„ç†ä¸­ï¼Œæ— æ³•é‡æ–°å¤„ç†');
        }

        // é‡ç½®æ–‡æ¡£çŠ¶æ€
        await DocumentModel.updateStatus(docId, DocumentIngestStatus.UPLOADED, undefined, trx);

        // åˆ›å»ºæ–°çš„å¤„ç†ä½œä¸š
        const processingJobs = await this.createProcessingJob(document, trx, jobTypes);

        console.log(`ğŸ”„ å·²åˆ›å»ºé‡æ–°å¤„ç†ä½œä¸š: ${docId}`);

        return Array.isArray(processingJobs) ? processingJobs : [processingJobs];

      } catch (error) {
        console.error('é‡æ–°å¤„ç†æ–‡æ¡£å¤±è´¥:', error);
        throw new Error(`é‡æ–°å¤„ç†æ–‡æ¡£å¤±è´¥: ${getErrorMessage(error)}`);
      }
    });
  }

  /**
   * è·å–æ–‡æ¡£å¤„ç†è¿›åº¦
   * @param docId æ–‡æ¡£ID
   * @param userId ç”¨æˆ·ID
   * @returns å¤„ç†è¿›åº¦ä¿¡æ¯
   */
  public static async getDocumentProgress(
    docId: string,
    userId: string
  ): Promise<{
    document: Document;
    currentJob?: ProcessingJob;
    progress: {
      stage: string;
      percentage: number;
      message: string;
      estimatedTimeRemaining?: number;
    };
  }> {
    try {
      // è·å–æ–‡æ¡£
      const document = await DocumentModel.findById(docId);
      if (!document) {
        throw new Error('æ–‡æ¡£ä¸å­˜åœ¨');
      }

      if (document.user_id !== userId) {
        throw new Error('æ— æƒé™æŸ¥çœ‹è¯¥æ–‡æ¡£è¿›åº¦');
      }

      // è·å–å½“å‰å¤„ç†ä½œä¸š
      const jobs = await ProcessingJobModel.findByDocument(docId, { 
        status: JobStatus.PROCESSING 
      }, 1, 0);
      const currentJob = jobs[0];

      // è®¡ç®—è¿›åº¦
      const progress = this.calculateDocumentProgress(document, currentJob);

      return {
        document,
        ...(currentJob !== undefined ? { currentJob } : {}),
        progress
      };

    } catch (error) {
      console.error('è·å–æ–‡æ¡£è¿›åº¦å¤±è´¥:', error);
      throw new Error(`è·å–æ–‡æ¡£è¿›åº¦å¤±è´¥: ${getErrorMessage(error)}`);
    }
  }

  /**
   * åˆ›å»ºå¤„ç†ä½œä¸š
   * @param document æ–‡æ¡£
   * @param trx äº‹åŠ¡
   * @param jobTypes æŒ‡å®šçš„ä½œä¸šç±»å‹
   * @returns åˆ›å»ºçš„ä½œä¸š
   */
  private static async createProcessingJob(
    document: Document,
    trx: Knex.Transaction,
    jobTypes?: JobType[]
  ): Promise<ProcessingJob> {
    try {
      // æ ¹æ®æ–‡æ¡£ç±»å‹ç¡®å®šä½œä¸šç±»å‹
      let jobType: JobType;
      if (jobTypes && jobTypes.length > 0 && jobTypes[0] !== undefined) {
        jobType = jobTypes[0] as JobType; // ç›®å‰åªå¤„ç†ç¬¬ä¸€ä¸ªä½œä¸šç±»å‹
      } else {
        jobType = this.getJobTypeForDocument(document);
      }

      // åˆ›å»ºä½œä¸šè¯·æ±‚
      const createJobRequest: CreateJobRequest = {
        doc_id: document.doc_id,
        user_id: document.user_id,
        job_type: jobType,
        priority: 5,
        queue_name: 'document-processing',
        max_attempts: 3,
        retry_delay_seconds: 300, // 5åˆ†é’Ÿ
        job_config: {
          timeout: 600000, // 10åˆ†é’Ÿè¶…æ—¶
          preserveOriginal: true
        },
        input_params: {
          filePath: document.storage_path,
          bucket: document.storage_bucket,
          mimeType: document.mime_type,
          parseConfig: document.parse_config,
          chunkConfig: document.chunk_config
        },
        file_path: document.storage_path
      };

      // åˆ›å»ºä½œä¸š
      const job = await ProcessingJobModel.create(createJobRequest, trx);

      console.log(`âš™ï¸ å·²åˆ›å»ºå¤„ç†ä½œä¸š: ${job.job_id} (ç±»å‹: ${jobType})`);

      return job;

    } catch (error) {
      console.error('åˆ›å»ºå¤„ç†ä½œä¸šå¤±è´¥:', error);
      throw new Error(`åˆ›å»ºå¤„ç†ä½œä¸šå¤±è´¥: ${getErrorMessage(error)}`);
    }
  }

  /**
   * æ ¹æ®æ–‡æ¡£ç±»å‹è·å–å¯¹åº”çš„ä½œä¸šç±»å‹
   * @param document æ–‡æ¡£
   * @returns ä½œä¸šç±»å‹
   */
  private static getJobTypeForDocument(document: Document): JobType {
    switch (document.mime_type) {
      case 'application/pdf':
        return JobType.PARSE_PDF;
      case 'text/markdown':
      case 'text/x-markdown':
        return JobType.PARSE_MARKDOWN;
      case 'text/plain':
        return JobType.PARSE_TEXT;
      default:
        return JobType.PARSE_PDF; // é»˜è®¤ä½¿ç”¨PDFè§£æ
    }
  }

  /**
   * è®¡ç®—æ–‡æ¡£å¤„ç†è¿›åº¦
   * @param document æ–‡æ¡£
   * @param currentJob å½“å‰ä½œä¸š
   * @returns è¿›åº¦ä¿¡æ¯
   */
  private static calculateDocumentProgress(
    document: Document,
    currentJob?: ProcessingJob
  ): {
    stage: string;
    percentage: number;
    message: string;
    estimatedTimeRemaining?: number;
  } {
    // çŠ¶æ€åˆ°è¿›åº¦çš„æ˜ å°„
    const stageProgress: Record<DocumentIngestStatus, { stage: string; percentage: number; message: string }> = {
      [DocumentIngestStatus.UPLOADING]: { stage: 'ä¸Šä¼ ä¸­', percentage: 5, message: 'æ­£åœ¨ä¸Šä¼ æ–‡ä»¶...' },
      [DocumentIngestStatus.UPLOADED]: { stage: 'å·²ä¸Šä¼ ', percentage: 10, message: 'æ–‡ä»¶ä¸Šä¼ å®Œæˆï¼Œç­‰å¾…å¤„ç†...' },
      [DocumentIngestStatus.PARSING]: { stage: 'è§£æä¸­', percentage: 40, message: 'æ­£åœ¨è§£ææ–‡æ¡£å†…å®¹...' },
      [DocumentIngestStatus.PARSED]: { stage: 'è§£æå®Œæˆ', percentage: 60, message: 'æ–‡æ¡£è§£æå®Œæˆï¼Œå‡†å¤‡åˆ†å—...' },
      [DocumentIngestStatus.CHUNKING]: { stage: 'åˆ†å—ä¸­', percentage: 80, message: 'æ­£åœ¨è¿›è¡Œæ–‡æ¡£åˆ†å—...' },
      [DocumentIngestStatus.CHUNKED]: { stage: 'åˆ†å—å®Œæˆ', percentage: 90, message: 'æ–‡æ¡£åˆ†å—å®Œæˆ...' },
      [DocumentIngestStatus.EMBEDDING]: { stage: 'å‘é‡åŒ–ä¸­', percentage: 95, message: 'æ­£åœ¨ç”Ÿæˆå‘é‡åµŒå…¥...' },
      [DocumentIngestStatus.READY]: { stage: 'å®Œæˆ', percentage: 100, message: 'æ–‡æ¡£å¤„ç†å®Œæˆï¼Œå¯ç”¨äºæ£€ç´¢' },
      [DocumentIngestStatus.FAILED]: { stage: 'å¤±è´¥', percentage: 0, message: 'å¤„ç†å¤±è´¥ï¼Œè¯·é‡è¯•' }
    };

    const baseProgress = stageProgress[document.ingest_status];

    // å¦‚æœæœ‰å½“å‰ä½œä¸šï¼Œä½¿ç”¨æ›´ç²¾ç¡®çš„è¿›åº¦
    if (currentJob && currentJob.progress_percentage > 0) {
      const jobProgress = currentJob.progress_percentage;
      const adjustedPercentage = Math.round(baseProgress.percentage + (jobProgress / 100) * 20);
      
      const estimatedTimeRemaining = this.estimateTimeRemaining(currentJob);
      return {
        stage: baseProgress.stage,
        percentage: Math.min(adjustedPercentage, 99), // ç¡®ä¿ä¸è¶…è¿‡99%
        message: currentJob.progress_message || baseProgress.message,
        ...(estimatedTimeRemaining !== undefined ? { estimatedTimeRemaining } : {})
      };
    }

    return baseProgress;
  }

  /**
   * ä¼°ç®—å‰©ä½™å¤„ç†æ—¶é—´
   * @param job å¤„ç†ä½œä¸š
   * @returns ä¼°ç®—çš„å‰©ä½™æ—¶é—´ï¼ˆç§’ï¼‰
   */
  private static estimateTimeRemaining(job: ProcessingJob): number | undefined {
    if (!job.started_at || job.progress_percentage <= 0) {
      return undefined;
    }

    const elapsedMs = Date.now() - job.started_at.getTime();
    const elapsedSeconds = Math.floor(elapsedMs / 1000);
    const progressRatio = job.progress_percentage / 100;
    
    if (progressRatio > 0) {
      const totalEstimatedSeconds = elapsedSeconds / progressRatio;
      const remainingSeconds = Math.max(0, totalEstimatedSeconds - elapsedSeconds);
      return Math.round(remainingSeconds);
    }

    return undefined;
  }
}

// å¯¼å‡ºæœåŠ¡ç±»
export default DocumentService;